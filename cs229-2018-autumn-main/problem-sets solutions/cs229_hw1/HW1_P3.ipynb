{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOfM07qBV7P7MozX8S2++MS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["3 a)\n","\n","Exponential family distributions are distributions of the form $p(y,\\eta)=b(y)\\exp(\\eta^TT(y)-a(\\eta))$.\n","\n","$\\exp(-\\lambda)\\lambda^y/y!=\\exp(-\\lambda)\\exp(y\\log\\lambda)/y!$.\n","\n","Let $\\eta=\\log\\lambda$, then $T(y)=y$, $a(\\eta)=e^\\eta$, $b(y)=y!$.\n","\n","3 b)\n","\n","The canonical response function $g(\\eta)=E[T(y)|\\eta]=E[y|\\eta]=\\lambda=e^\\eta$.\n","\n","3 c)\n","\n","It seems that the lecture note hints that the update rule should be $\\theta=\\theta + \\alpha (y^{(i)}-h_\\theta(x^{(i)}))x_j^{(i)}$.\n","\n","For an exponential family distribution $p(y,\\eta)=b(y)\\exp(\\eta^T T(y)-a(\\eta))$ with $\\eta=\\theta^T x$ and $T(y)=y$, the log-liklihood $L(\\theta)=\\sum_{i=1}^m \\log(p(y^{(i)}|x^{(i)},\\theta))$. $\\log p(y|x,\\theta)=\\log b(y)+\\theta^T x T(y)-a(\\theta^T x)$, so $\\partial(\\log(p(y|x,\\theta)))/\\partial \\theta_j=x_jT(y)-x_ja'(\\theta^Tx)$. With a Poisson response variable, the stochastic gradient ascent update rule is $\\theta_j=\\theta_j+\\alpha (y-e^{\\theta^T x})x_j$.\n"],"metadata":{"id":"jdF-thAtnwkF"}},{"cell_type":"markdown","source":["3 d)"],"metadata":{"id":"0Hs6LUAmc5wf"}},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfgpFUjhz68-","executionInfo":{"status":"ok","timestamp":1719563765396,"user_tz":-480,"elapsed":4147,"user":{"displayName":"Henry Z","userId":"04217387948606298563"}},"outputId":"1357a2e7-22b4-4be3-ebb4-d0f9c6ccbfbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","2500\n","[11.29971308 10.79968765  2.00013962  4.40023622]\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import numpy as np\n","import sys\n","sys.path.append('/content/drive/MyDrive/cs229/problem-sets/PS1/src') # Python interpreter searches for modules/packages to import from a list of directories called 'PYTHONPATH', which is added to here\n","import util # import the entire '.py' file, executing any top-level code, and copying all functions, variables, and classes\n","from linear_model import LinearModel\n","sys.path.remove('/content/drive/MyDrive/cs229/problem-sets/PS1/src')  # remove added path from 'PYTHONPATH'\n","\n","\n","def main(lr, train_path, eval_path, pred_path):\n","    \"\"\"Problem 3(d): Poisson regression with gradient ascent.\n","    Args:\n","        lr: Learning rate for gradient ascent.\n","        train_path: Path to CSV file containing dataset for training.\n","        eval_path: Path to CSV file containing dataset for evaluation.\n","        pred_path: Path to save predictions.\n","    \"\"\"\n","    # Load training set\n","    x_train, y_train = util.load_dataset(train_path, add_intercept=False)\n","    # *** START CODE HERE ***\n","    # Fit a Poisson Regression model\n","    model = PoissonRegression()\n","    theta = model.fit(x_train, y_train)\n","    print(theta)\n","    # Run on the validation set, and use np.savetxt to save outputs to pred_path\n","    x_valid, _ = util.load_dataset(eval_path, add_intercept = False)\n","    y_pred = model.predict(x_valid)\n","    np.savetxt(pred_path, y_pred, delimiter=',', fmt='%f')\n","    # *** END CODE HERE ***\n","\n","\n","class PoissonRegression(LinearModel):\n","    \"\"\"Poisson Regression.\n","    Example usage:\n","        > clf = PoissonRegression(step_size=lr)\n","        > clf.fit(x_train, y_train)\n","        > clf.predict(x_eval)\n","    \"\"\"\n","\n","    def fit(self, x, y):\n","        \"\"\"Run gradient ascent to maximize likelihood for Poisson regression.\n","        Args:\n","            x: Training example inputs. Shape (m, n).\n","            y: Training example labels. Shape (m,).\n","        \"\"\"\n","        # *** START CODE HERE ***\n","        m, n = x.shape\n","        self.theta = np.zeros(n)\n","        step = np.ones(n)\n","        while np.linalg.norm(step, 1) >= 1e-5:\n","          step = 1e-10 * ((y - np.exp(x @ self.theta)).T @ x)\n","          self.theta += step\n","        return self.theta\n","        # *** END CODE HERE ***\n","\n","    def predict(self, x):\n","        \"\"\"Make a prediction given inputs x.\n","        Args:\n","            x: Inputs of shape (m, n).\n","        Returns:\n","            Floating-point prediction for each input, shape (m,).\n","        \"\"\"\n","        # *** START CODE HERE ***\n","        return np.exp(x @ self.theta) # return exp(\\theta^T x)\n","        # *** END CODE HERE ***\n","\n","\n","if __name__ == '__main__':\n","  lr = 1e-5\n","  train_path = '/content/drive/MyDrive/cs229/problem-sets/PS1/data/ds4_train.csv'\n","  valid_path = '/content/drive/MyDrive/cs229/problem-sets/PS1/data/ds4_valid.csv'\n","  pred_path = '/content/drive/MyDrive/cs229/problem-sets/PS1/data/ds4_pred.csv'\n","  main(lr, train_path, valid_path, pred_path)"]}]}