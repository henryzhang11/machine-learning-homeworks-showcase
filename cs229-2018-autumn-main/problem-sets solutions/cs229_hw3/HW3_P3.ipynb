{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnWE7qC+UJPi83hccajRfN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","3 a)\n","\n","$E_{y\\sim p(y;\\theta)}[\\frac{\\partial p(y;\\theta)/\\partial \\theta}{p(y;\\theta)}]$$=\\int_\\mathbb{R}\\frac{\\partial p(y;\\theta)/\\partial \\theta}{p(y;\\theta)}p(y;\\theta) dy$$=\\int_\\mathbb{R}\\partial p(y;\\theta)/\\partial\\theta dy$$=\\partial(\\int_\\mathbb{R}p(y;\\theta)dy)/\\partial\\theta$$=\\partial 1/\\partial\\theta$$=0$.\n","\n","3 b)\n","\n","Since $E_{y\\sim p(y;\\theta)}[\\nabla_{\\theta'}\\log p(y;\\theta')|_{\\theta'=\\theta}]=0$, $I(\\theta)=E_{y\\sim p(y;\\theta)}[\\nabla_{\\theta'}\\log p(y;\\theta')\\nabla_{\\theta'}\\log p(y;\\theta')^T|_{\\theta'=\\theta}]$.\n","\n","3 c)\n","\n","$\\frac{\\partial^2\\log p(y;\\theta')}{\\partial\\theta_1\\partial\\theta_2}$$=\\frac{\\partial}{\\partial\\theta_2}(\\frac{\\partial p(y;\\theta)/\\partial\\theta_1}{p(y;\\theta)})$$=\\frac{\\partial^2p(y;\\theta)/\\partial\\theta_1\\partial\\theta_2p(y;\\theta)-\\partial p(y;\\theta)/\\partial\\theta_1\\cdot\\partial p(y;\\theta)/\\partial\\theta_2}{p(y;\\theta)^2}$.\n","\n","$E_{y\\sim p(y;\\theta)}[\\frac{\\partial^2p(y;\\theta)/\\partial\\theta_1\\partial\\theta_2}{p(y;\\theta)}]$$=\\int_\\mathbb{R} \\frac{\\partial^2p(y;\\theta)/\\partial\\theta_1\\partial\\theta_2}{p(y;\\theta)} p(y;\\theta)dy$$=\\int_\\mathbb{R} \\frac{\\partial^2 p(y;\\theta)}{\\partial\\theta_1\\partial \\theta_2}dy$$=\\frac{\\partial^2}{\\partial\\theta_1\\partial\\theta_2}(\\int_\\mathbb{R} p(y;\\theta) dy)$$=\\frac{\\partial^2}{\\partial\\theta_1\\partial\\theta_2}(1)$$=0$.\n","\n","So, $E_{y\\sim p(y;\\theta)}[-\\nabla_\\theta^2 \\log p(y;\\theta)|_{\\theta'=\\theta}]$$=E_{y\\sim p(y;\\theta)}[\\frac{\\partial p(y;\\theta)/\\partial\\theta_1\\cdot\\partial p(y;\\theta)/\\partial\\theta_2}{p(y;\\theta)^2}]$$=E_{y\\sim p(y;\\theta)}[\\frac{\\partial \\log p(y;\\theta)}{\\partial\\theta_1}\\frac{\\partial\\log p(y;\\theta)}{\\partial\\theta_2}]$$=I(\\theta)$.\n","\n","3 d)\n","\n","$f(\\tilde{\\theta})=D_{KL}(p_\\theta||p_{\\tilde{\\theta}})$$=\\int_\\mathbb{R}p(y;\\theta)\\log(\\frac{p(y;\\theta)}{p(y;\\tilde{\\theta})})dy$.\n","So, $f(\\tilde{\\theta})\\approx f(\\theta)+(\\tilde{\\theta}-\\theta)^T\\nabla_{\\theta'}f(\\theta')|_{\\theta'=\\theta}+\\frac{1}{2}(\\tilde{\\theta}-\\theta)^T(\\nabla^2_{\\theta'}f(\\theta')|_{\\theta'=\\theta})(\\tilde{\\theta}-\\theta)$$=(\\tilde{\\theta}-\\theta)^T\\nabla_{\\theta'}f(\\theta')|_{\\theta'=\\theta}+\\frac{1}{2}(\\tilde{\\theta}-\\theta)^T(\\nabla^2_{\\theta'}f(\\theta')|_{\\theta'=\\theta})(\\tilde{\\theta}-\\theta)$$=d^T\\nabla_{\\theta'} f(\\theta')|_{\\theta'=\\theta}+\\frac{1}{2}d^T(\\nabla^2_{\\theta'}f(\\theta')|_{\\theta'=\\theta})d$$=d^TE_{y\\sim p(y;\\theta)}[-\\nabla_{\\theta'}\\log p(y;\\theta')|_{\\theta'=\\theta}]+\\frac{1}{2}d^TE_{y\\sim p(y;\\theta)}[-\\nabla_{\\theta}^2\\log p(y;\\theta)]d$$=\\frac{1}{2}d^TE_{y\\sim p(y;\\theta)}[-\\nabla_{\\theta}^2\\log p(y;\\theta)]d$$=\\frac{1}{2}d^T I(\\theta) d$.\n","\n","3 e)\n","\n","Approximate the original optimization problem with $\\arg\\max_d d^T\\nabla_{\\theta'}\\ell(\\theta')|_{\\theta'=\\theta}$ s.t. $\\frac{1}{2}d^T I(\\theta) d=c$. The Lagrangian equals $d^T\\nabla_{\\theta'}\\ell(\\theta')|_{\\theta'=\\theta}-\\lambda[\\frac{1}{2}d^TI(\\theta)d-c]$. $\\nabla_d\\mathcal{L}(d,\\lambda)=0$ and $\\nabla_{\\lambda}\\mathcal{L}(d,\\lambda)=0$ imply $\\nabla_{\\theta'}\\ell(\\theta')|_{\\theta'=\\theta}-\\lambda d^TI(\\theta)=0$ and $\\frac{1}{2}d^TI(\\theta)d-c=0$. $d=(I(\\theta)^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T/\\lambda$. Plugging this expression for $d$ into $\\frac{1}{2}d^TI(\\theta)d=c$ gives $\\frac{1}{2}(\\nabla_{\\theta'}\\ell(\\theta')(I(\\theta)^{-1})/\\lambda)I(\\theta)(((I(\\theta)^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T/\\lambda)=c$. This implies $\\lambda = \\sqrt{\\frac{1}{2c}(\\nabla_{\\theta'}\\ell(\\theta')(I(\\theta)^{-1}))I(\\theta)(((I(\\theta)^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T)}$$= \\sqrt{\\frac{1}{2c}\\nabla_{\\theta'}\\ell(\\theta')(((I(\\theta)^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T)}$. Plugging the expression for $\\lambda$ back into the expression for $d$ gives $d=(I(\\theta)^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T/(\\sqrt{\\frac{1}{2c}\\nabla_{\\theta'}\\ell(\\theta')(((I(\\theta)^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T)})$.\n","\n","3 f)\n","\n","Newton's method is given by $\\theta = \\theta - H^{-1}\\nabla_\\theta\\ell(\\theta)$ with $\\ell(\\theta)$ the likelihood function and $H=\\nabla^2_\\theta \\ell(\\theta)$. By exercise 4 of homework 1, $\\nabla_\\theta \\ell(\\theta) = -x(y-a'(\\eta))$ and $H=xa''(\\eta)x^T$.\n","By part 3 e), the natural gradient has the direction of $(I(\\theta)^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T$$=(E_{y\\sim p(y;\\theta)}[-\\nabla^2_{\\theta'}\\ell(\\theta')]^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T$$=(E_{y\\sim p(y;\\theta)}[-xa''(\\eta)x^T]^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T$$=-((xa''(\\eta)x)^{-1})^T\\nabla_{\\theta'}\\ell(\\theta')^T=H^{-1}\\nabla_{\\theta}\\ell(\\theta)$, with the expectation dropping out because the expression doesn't involve $y$."],"metadata":{"id":"rtgZ8p3reooh"}},{"cell_type":"markdown","source":[],"metadata":{"id":"Bn0oRm8QRctO"}}]}